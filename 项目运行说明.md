# 新闻实时分析系统 - 快速运行指南

## 推荐环境：Linux (Ubuntu 20.04+)

### 为什么选择Linux？
- Spark和Kafka在Linux上更稳定
- 配置更简单，兼容性更好
- 性能更优，资源占用更少

## 一、环境准备 (Ubuntu虚拟机)

### 1. 创建Ubuntu虚拟机
- 推荐VMware或VirtualBox
- Ubuntu 20.04 LTS
- 内存: 8GB, CPU: 4核, 硬盘: 50GB

### 2. 基础软件安装
```bash
# 更新系统
sudo apt update && sudo apt upgrade -y

# 安装Java 8
sudo apt install openjdk-8-jdk -y
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
echo 'export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64' >> ~/.bashrc

# 安装Python和pip
sudo apt install python3 python3-pip -y
```

### 3. 安装Kafka
```bash
# 下载Kafka
cd ~
wget https://downloads.apache.org/kafka/2.8.2/kafka_2.13-2.8.2.tgz
tar -xzf kafka_2.13-2.8.2.tgz
cd kafka_2.13-2.8.2
```

### 4. 安装MySQL
```bash
sudo apt install mysql-server -y
sudo mysql_secure_installation

# 创建数据库 (使用实际验证的配置)
sudo mysql -u root -p
CREATE DATABASE news_analytics CHARACTER SET utf8mb4;
SET @@global.validate_password.policy=LOW;
SET @@global.validate_password.length=6;
CREATE USER 'analytics_user'@'localhost' IDENTIFIED BY 'pass123';
GRANT ALL PRIVILEGES ON news_analytics.* TO 'analytics_user'@'localhost';
FLUSH PRIVILEGES;
EXIT;
```

### 5. 安装Spark (推荐使用pip方式)
```bash
# 方式1: 使用pip安装 (推荐，已验证)
pip3 install pyspark==3.4.1

# 设置环境变量 (重要: 使用pip安装的路径)
export SPARK_HOME=/home/$USER/.local/lib/python3.10/site-packages/pyspark
echo "export SPARK_HOME=/home/$USER/.local/lib/python3.10/site-packages/pyspark" >> ~/.bashrc
source ~/.bashrc

# 验证安装
spark-submit --version
```

## 二、项目部署

### 1. 获取项目代码
```bash
git clone [你的项目地址]
cd Business-Intelligence-Final-Project
```

### 2. 安装Python依赖
```bash
pip3 install -r requirements.txt

# 下载NLTK数据
python3 -c "import nltk; nltk.download('punkt'); nltk.download('vader_lexicon')"
```

### 3. 初始化数据库
```bash
# 使用实际验证的数据库配置
mysql -u analytics_user -p'pass123' news_analytics < sql/init_database.sql
```

## 三、启动系统 (按顺序执行)

### 1. 启动Zookeeper (终端1)
```bash
zookeeper-server-start.sh $KAFKA_HOME/config/zookeeper.properties
```

### 2. 启动Kafka (终端2)
```bash
kafka-server-start.sh $KAFKA_HOME/config/server.properties
```

### 3. 创建Kafka Topic (终端3)
```bash
kafka-topics.sh --create --topic news-impressions --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
```

### 4. 启动数据模拟器 (终端4)
```bash
cd ~/Business-Intelligence-Final-Project
python3 utils/data_simulator.py --rate 5 --duration 120
```

### 5. 启动Spark分析器 (终端5)
```bash
cd ~/Business-Intelligence-Final-Project
python3 main.py
```

## 四、验证系统运行

### 1. 查看Kafka数据
```bash
kafka-console-consumer.sh --topic news_impression_logs --from-beginning --bootstrap-server localhost:9092
```

### 2. 查看Spark UI
浏览器访问: http://localhost:4040

### 3. 查看MySQL结果
```bash
mysql -u analytics_user -p'pass123' news_analytics

# 查看分析结果
SELECT COUNT(*) FROM user_behavior_analytics;
SELECT COUNT(*) FROM news_popularity_analytics;
SELECT * FROM trending_analytics ORDER BY trend_score DESC LIMIT 10;
```

### 4. 查看系统日志
```bash
tail -f logs/news_analytics.log
```

## 五、Windows环境 (备选方案)

如果必须在Windows上运行，建议使用WSL2：

### 1. 安装WSL2
```powershell
# 管理员PowerShell中执行
wsl --install -d Ubuntu-20.04
```

### 2. 在WSL2中按照Linux步骤操作
```bash
# 进入WSL2
wsl

# 然后按照上面的Linux步骤操作
```

## 六、性能优化配置

### 1. Spark配置 ($SPARK_HOME/conf/spark-defaults.conf)
```
spark.executor.memory=4g
spark.executor.cores=2
spark.sql.adaptive.enabled=true
spark.sql.adaptive.coalescePartitions.enabled=true
```

### 2. Kafka配置 (config/server.properties)
```
num.network.threads=8
num.io.threads=16
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
```

### 3. MySQL配置 (/etc/mysql/mysql.conf.d/mysqld.cnf)
```
[mysqld]
innodb_buffer_pool_size=2G
innodb_log_file_size=256M
max_connections=1000
```

## 七、常见问题

### Q1: Kafka连接失败
```bash
# 检查Kafka状态
netstat -tulpn | grep :9092

# 重启Kafka
cd ~/kafka_2.13-2.8.2
bin/kafka-server-stop.sh
bin/kafka-server-start.sh config/server.properties
```

### Q2: Spark内存不足
```bash
# 增加executor内存
export SPARK_EXECUTOR_MEMORY=2g
# 或修改spark-defaults.conf
```

### Q3: MySQL连接错误
```bash
# 检查MySQL状态
sudo systemctl status mysql

# 重启MySQL
sudo systemctl restart mysql
```

## 八、快速启动脚本

项目包含了快速启动脚本：
```bash
python3 start_project.py
```

这个脚本会：
- 检查依赖是否安装
- 检查服务是否运行
- 自动创建Kafka Topic
- 启动数据模拟器和分析器

## 九、系统监控

### 实时监控命令：
```bash
# 监控Kafka消息流
kafka-console-consumer --topic news_impression_logs --bootstrap-server localhost:9092

# 监控系统日志
tail -f logs/news_analytics.log

# 监控数据库写入
watch "mysql -u analytics_user -p[password] -e 'SELECT COUNT(*) as records FROM news_analytics.user_behavior_analytics;'"
```

## 十、项目结构说明

```
Business-Intelligence-Final-Project/
├── config/                    # 配置文件
├── src/                      # 核心代码
├── sql/                      # 数据库脚本
├── utils/                    # 工具脚本
├── logs/                     # 日志文件
├── checkpoints/              # Spark检查点
├── requirements.txt          # Python依赖
├── main.py                   # 主启动文件
└── start_project.py          # 快速启动脚本
```

这样你就可以成功运行整个新闻实时分析系统了！建议使用Linux环境以获得最佳性能和稳定性。 
